{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering exercices on Popular Halloween Costumes in 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Context\n",
    " > So it's Halloween again dear Kagglers! And what better way of celebrating than with some NLP! The dataset brings you the reviews of popular Halloween costumes sold on amazon as of November 2020. Content The dataset contains popular costumes from the Amazon website, for each costume there are user review texts including the review title and the review score, also you will find the publishing date and location. The data hasn't been preprocessed in any way so I think it can be a great exercise for aspiring data scientists who are looking to sharpen their skills in text preprocessing skills and feature extraction skills.\n",
    "\n",
    "Import data from this website: https://www.openml.org/search?type=data&status=active&id=43360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Charge les donnÃ©es\n",
    "data = fetch_openml(name=\"Popular-Halloween-2020--Costumes-Amazon-Reviews\") \n",
    "data = data[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  This wig is definitely not for adults\n",
      " We had several adults try this wig on with it as big as it can go and it still didn't fit anyone\n",
      " Not to mention this wig is just awkward over all as you no woman could wear it with a wig cap as it sits to high in the back\n",
      " Definitely not what we expected for how much this wig costs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in data[\"text\"][0].split(\".\"):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(\"title\", axis=1)\n",
    "y = data[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=1, stop_words='english') # max_df plus de 50%, min_df moins de 2\n",
    "X_tfidf = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_samples=4 should be >= n_clusters=5.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\Git\\Simplon\\simplon_datai_2025\\4-clustering\\Cluster_exercices.ipynb Cellule 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/Git/Simplon/simplon_datai_2025/4-clustering/Cluster_exercices.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m K:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/Git/Simplon/simplon_datai_2025/4-clustering/Cluster_exercices.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     km \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39mk)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/Git/Simplon/simplon_datai_2025/4-clustering/Cluster_exercices.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     km \u001b[39m=\u001b[39m km\u001b[39m.\u001b[39;49mfit(X_tfidf)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/Git/Simplon/simplon_datai_2025/4-clustering/Cluster_exercices.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     Sum_of_squared_distances\u001b[39m.\u001b[39mappend(km\u001b[39m.\u001b[39minertia_)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1480\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \n\u001b[0;32m   1447\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[39m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1471\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m   1472\u001b[0m     X,\n\u001b[0;32m   1473\u001b[0m     accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1477\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1478\u001b[0m )\n\u001b[1;32m-> 1480\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params_vs_input(X)\n\u001b[0;32m   1482\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[0;32m   1483\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412\u001b[0m, in \u001b[0;36mKMeans._check_params_vs_input\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_params_vs_input\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m-> 1412\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_check_params_vs_input(X, default_n_init\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m   1414\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_algorithm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm\n\u001b[0;32m   1415\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_algorithm \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:866\u001b[0m, in \u001b[0;36m_BaseKMeans._check_params_vs_input\u001b[1;34m(self, X, default_n_init)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_params_vs_input\u001b[39m(\u001b[39mself\u001b[39m, X, default_n_init\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    864\u001b[0m     \u001b[39m# n_clusters\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clusters:\n\u001b[1;32m--> 866\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    867\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mn_samples=\u001b[39m\u001b[39m{\u001b[39;00mX\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m should be >= n_clusters=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_clusters\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    868\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39m# tol\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tol \u001b[39m=\u001b[39m _tolerance(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol)\n",
      "\u001b[1;31mValueError\u001b[0m: n_samples=4 should be >= n_clusters=5."
     ]
    }
   ],
   "source": [
    "# use the elbow method to find the optimal number of clusters\n",
    "Sum_of_squared_distances = []\n",
    "K = range(1,20)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(X_tfidf)\n",
    "    Sum_of_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "kmeans = KMeans(n_clusters=len(np.unique(y_train_tfidf)), n_init=\"auto\", random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
