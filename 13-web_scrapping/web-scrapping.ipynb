{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the links, the titles and the paragraphs of the articles from the main article and sort them by similarity to the main article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web_scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link': 'https://en.wikipedia.org/wiki/machine_learning',\n",
       " 'title': 'Machine learning',\n",
       " 'paragraph': 'Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5]\\n'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the main article\n",
    "requete = requests.get('https://en.wikipedia.org/wiki/machine_learning')\n",
    "page = BeautifulSoup(requete.text, 'html.parser')\n",
    "wiki_main = {}\n",
    "wiki_main['link'] = 'https://en.wikipedia.org/wiki/machine_learning'\n",
    "wiki_main['title'] = page.find('h1').text\n",
    "wiki_main['paragraph'] = page.find('p').text\n",
    "wiki_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the links of the articles\n",
    "links = page.find_all('a')\n",
    "http_links = [f\"{link.get('href')}\" for link in links if link.get('href') and link.get('href').startswith('/wiki')]  \n",
    "wiki_list = []\n",
    "wiki_dict_sans_doublon = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'link': '/wiki/Main_Page', 'title': 'Main Page', 'paragraph': 'Ernest Roberts (21\\xa0February 1868\\xa0– 2\\xa0December 1913) was a Labor member of the South Australian House of Assembly, and then the Australian House of Representatives. Roberts emigrated to Australia from the UK and worked in Port Pirie, South Australia, where he was a member of its town council. In 1896, aged 28, he became the youngest person elected to the House of Assembly and quickly gained a reputation for his oratory. He served in South Africa twice during the Second Boer War, rising to the rank of captain. During his second period of service his term in the South Australian parliament expired. After returning home, he was the editor of a political newspaper before being elected to the House of Assembly again in 1905. He was elected to the federal House of Representatives in a by-election in 1908 and was appointed as an honorary minister in 1911. After a fiery parliamentary debate on 2\\xa0December 1913, Roberts collapsed and died, aged 45. His state funeral was attended by around 6,000 people. (Full\\xa0article...)\\n'}, {'link': '/wiki/Wikipedia:Contents', 'title': 'Wikipedia:Contents', 'paragraph': '\\n'}, {'link': '/wiki/Portal:Current_events', 'title': 'Portal:Current events', 'paragraph': 'Edit instructions\\n'}, {'link': '/wiki/Special:Random', 'title': 'Albpetrol', 'paragraph': 'Albpetrol is an Albanian upstream petroleum production and marketing company, which also monitors state petroleum agreements in Albania. Its stock is owned by the Albanian state. The company is headquartered in Patos and has a representative office in Tirana. The CEO of Albpetrol is Mr. Baftjar Zeqaj. Albpetrol is managing more than 1200 oil wells in the existing settlements of Patos, Ballsh, Karbunarë, Kuçovë, Gorisht-Kocul, Cakran-Mollaj and Amonicë.\\n'}, {'link': '/wiki/Help:Contents', 'title': 'Help:Contents', 'paragraph': '\\n\\n'}]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of dictionaries containing the links, titles, and paragraphs of the articles\n",
    "for link in http_links:\n",
    "    wiki_dict = {}\n",
    "    requete = requests.get(\"https://en.wikipedia.org\" + link)\n",
    "    page = BeautifulSoup(requete.text, 'html.parser')\n",
    "    h_1 = page.find('h1')\n",
    "    p_1 = page.find('p')\n",
    "    if p_1 is not None and p_1.text not in wiki_dict_sans_doublon: # We filter the duplicates\n",
    "        wiki_dict_sans_doublon.append(p_1.text)\n",
    "        wiki_dict[\"link\"] = link\n",
    "        wiki_dict[\"title\"] = h_1.text\n",
    "        wiki_dict[\"paragraph\"] = p_1.text\n",
    "        wiki_list.append(wiki_dict)\n",
    "print(wiki_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an OpenAI client\n",
    "client = OpenAI()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding of the paragraph and title for the wiki_main article\n",
    "response = client.embeddings.create(\n",
    "    input=wiki_main['title'] + wiki_main['paragraph'],\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "wiki_main[\"embeddings\"] = response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(A, B):\n",
    "    #Find intersection of two sets\n",
    "    nominator = A.intersection(B)\n",
    "\n",
    "    #Find union of two sets\n",
    "    denominator = A.union(B)\n",
    "\n",
    "    #Take the ratio of sizes\n",
    "    similarity = len(nominator)/len(denominator)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding of the paragraph and title for each article in wiki_list\n",
    "for wiki in wiki_list:\n",
    "    response = client.embeddings.create(\n",
    "        input=wiki['title'] + wiki['paragraph'],\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    wiki[\"embeddings\"] = response.data[0].embedding\n",
    "    # Calculate the similarity between the main article and each article in wiki_list using the dot product of their embeddings\n",
    "    wiki['similarity_embedding_dot_product'] = np.dot(wiki_main['embeddings'], wiki['embeddings'])\n",
    "    # Calculate the similarity between the main article and each article in wiki_list using the cosine similarity of their embeddings\n",
    "    wiki['similarity_embedding_cosine_similarity'] = np.dot(wiki_main['embeddings'], wiki['embeddings']) / (np.linalg.norm(wiki_main['embeddings']) * np.linalg.norm(wiki['embeddings']))\n",
    "    # Calculate the similarity between the main article and each article in wiki_list using the jaccard similarity of their embeddings\n",
    "    wiki['similarity_embedding_jaccard_similarity'] = jaccard_similarity(set(wiki_main['embeddings']), set(wiki['embeddings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000882947506\n",
      "https://en.wikipedia.org/wiki/Machine_learning\n",
      "Machine learning\n",
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5]\n",
      "\n",
      "0.9274254193423537\n",
      "https://en.wikipedia.org/wiki/Category:Machine_learning\n",
      "Category:Machine learning\n",
      "Machine learning is a branch of statistics and computer science which studies algorithms and architectures that learn from observed facts.\n",
      "\n",
      "0.911577885978255\n",
      "https://en.wikipedia.org/wiki/Automated_machine_learning\n",
      "Automated machine learning\n",
      "Automated machine learning (AutoML) is the process of automating the tasks of applying machine learning to real-world problems. \n",
      "\n",
      "0.8803775597848987\n",
      "https://en.wikipedia.org/wiki/Deep_learning\n",
      "Deep learning\n",
      "Deep learning is the subset of machine learning methods which are based on artificial neural networks with representation learning. The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.[2]\n",
      "\n",
      "0.8790053315862202\n",
      "https://en.wikipedia.org/wiki/Rule-based_machine_learning\n",
      "Rule-based machine learning\n",
      "Rule-based machine learning (RBML) is a term in computer science intended to encompass any machine learning method that identifies, learns, or evolves 'rules' to store, manipulate or apply.[1][2][3] The defining characteristic of a rule-based machine learner is the identification and utilization of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learners that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.[clarification needed][citation needed]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort the wiki_list by similarity using the dot product of their embeddings\n",
    "wiki_list.sort(key=lambda x: x['similarity_embedding_dot_product'], reverse=True)\n",
    "\n",
    "# Print the top 5 articles by similarity using the dot product of their embeddings\n",
    "for wiki in wiki_list[:5]:\n",
    "    print(wiki['similarity_embedding_dot_product'])\n",
    "    print(\"https://en.wikipedia.org\" + wiki['link'])\n",
    "    print(wiki['title'])\n",
    "    print(wiki['paragraph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998\n",
      "https://en.wikipedia.org/wiki/Machine_learning\n",
      "Machine learning\n",
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5]\n",
      "\n",
      "0.9274253257534554\n",
      "https://en.wikipedia.org/wiki/Category:Machine_learning\n",
      "Category:Machine learning\n",
      "Machine learning is a branch of statistics and computer science which studies algorithms and architectures that learn from observed facts.\n",
      "\n",
      "0.9115778982802039\n",
      "https://en.wikipedia.org/wiki/Automated_machine_learning\n",
      "Automated machine learning\n",
      "Automated machine learning (AutoML) is the process of automating the tasks of applying machine learning to real-world problems. \n",
      "\n",
      "0.880377487712539\n",
      "https://en.wikipedia.org/wiki/Deep_learning\n",
      "Deep learning\n",
      "Deep learning is the subset of machine learning methods which are based on artificial neural networks with representation learning. The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.[2]\n",
      "\n",
      "0.8790053072252554\n",
      "https://en.wikipedia.org/wiki/Rule-based_machine_learning\n",
      "Rule-based machine learning\n",
      "Rule-based machine learning (RBML) is a term in computer science intended to encompass any machine learning method that identifies, learns, or evolves 'rules' to store, manipulate or apply.[1][2][3] The defining characteristic of a rule-based machine learner is the identification and utilization of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learners that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.[clarification needed][citation needed]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort the wiki_list by similarity using the cosine similarity of their embeddings\n",
    "wiki_list.sort(key=lambda x: x['similarity_embedding_cosine_similarity'], reverse=True)\n",
    "\n",
    "# Print the top 5 articles by similarity using the cosine similarity of their embeddings\n",
    "for wiki in wiki_list[:5]:\n",
    "    print(wiki['similarity_embedding_cosine_similarity'])\n",
    "    print(\"https://en.wikipedia.org\" + wiki['link'])\n",
    "    print(wiki['title'])\n",
    "    print(wiki['paragraph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "https://en.wikipedia.org/wiki/Machine_learning\n",
      "Machine learning\n",
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5]\n",
      "\n",
      "0.0007079646017699115\n",
      "https://en.wikipedia.org/wiki/Cheminformatics\n",
      "Cheminformatics\n",
      "Cheminformatics (also known as chemoinformatics) refers to the use of physical chemistry theory with computer and information science techniques—so called \"in silico\" techniques—in application to a range of descriptive and prescriptive problems in the field of chemistry, including in its applications to biology and related molecular fields. Such in silico techniques are used, for example, by pharmaceutical companies and in academic settings to aid and inform the process of drug discovery, for instance in the design of well-defined combinatorial libraries of synthetic compounds, or to assist in structure-based drug design. The methods can also be used in chemical and allied industries, and such fields as environmental science and pharmacology, where chemical processes are involved or studied.[1]\n",
      "\n",
      "0.0007057163020465773\n",
      "https://en.wikipedia.org/wiki/Ontology_learning\n",
      "Ontology learning\n",
      "Ontology learning (ontology extraction, ontology generation, or ontology acquisition) is the automatic or semi-automatic creation of ontologies, including extracting the corresponding domain's terms and the relationships between the concepts that these terms represent from a corpus of natural language text, and encoding them with an ontology language for easy retrieval. As building ontologies manually is extremely labor-intensive and time-consuming, there is great motivation to automate the process.\n",
      "\n",
      "0.0007054673721340388\n",
      "https://en.wikipedia.org/wiki/SPSS_Modeler\n",
      "SPSS Modeler\n",
      "IBM SPSS Modeler is a data mining and text analytics software application from IBM. It is used to build predictive models and conduct other analytic tasks. It has a visual interface which allows users to leverage statistical and data mining algorithms without programming.\n",
      "\n",
      "0.00035549235691432633\n",
      "https://en.wikipedia.org/wiki/DeepDream\n",
      "DeepDream\n",
      "DeepDream is a computer vision program created by Google engineer Alexander Mordvintsev that uses a convolutional neural network to find and enhance patterns in images via algorithmic pareidolia, thus creating a dream-like appearance reminiscent of a psychedelic experience in the deliberately overprocessed images.[1][2][3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort the wiki_list by similarity using the jaccard similarity of their embeddings\n",
    "wiki_list.sort(key=lambda x: x['similarity_embedding_jaccard_similarity'], reverse=True)\n",
    "\n",
    "# Print the top 5 articles by similarity using the jaccard similarity of their embeddings\n",
    "for wiki in wiki_list[:5]:\n",
    "    print(wiki['similarity_embedding_jaccard_similarity'])\n",
    "    print(\"https://en.wikipedia.org\" + wiki['link'])\n",
    "    print(wiki['title'])\n",
    "    print(wiki['paragraph'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load the stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_en = stopwords.words('english')\n",
    "stop_words_ext = list(stop_en)\n",
    "vectorizer = CountVectorizer(stop_words=stop_words_ext, token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z_-]+\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine learning', 'Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5]\\n', 'Cheminformatics', 'Cheminformatics (also known as chemoinformatics) refers to the use of physical chemistry theory with computer and information science techniques—so called \"in silico\" techniques—in application to a range of descriptive and prescriptive problems in the field of chemistry, including in its applications to biology and related molecular fields. Such in silico techniques are used, for example, by pharmaceutical companies and in academic settings to aid and inform the process of drug discovery, for instance in the design of well-defined combinatorial libraries of synthetic compounds, or to assist in structure-based drug design. The methods can also be used in chemical and allied industries, and such fields as environmental science and pharmacology, where chemical processes are involved or studied.[1]\\n', 'Ontology learning']\n"
     ]
    }
   ],
   "source": [
    "# Create the corpus by concatenating the title and the paragraph of each article\n",
    "corpus = []\n",
    "for wiki in wiki_list:\n",
    "    corpus.append(wiki['title'])\n",
    "    corpus.append(wiki['paragraph'])\n",
    "print(corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1152x5344 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19883 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the vectorizer to the corpus\n",
    "vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector for the main article\n",
    "wiki_main['vector'] = vectorizer.transform([wiki_main['title'] + wiki_main['paragraph']]).toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity between the main article and each article in wiki_list using the dot product of their vectors\n",
    "for wiki in wiki_list:\n",
    "    wiki['vector'] = vectorizer.transform([wiki['title'] + wiki['paragraph']]).toarray()[0]\n",
    "    # Calculate the similarity between the main article and each article in wiki_list using the dot product of their vectors\n",
    "    wiki['similarity_vector_dot_product'] = np.dot(wiki_main['vector'], wiki['vector'])\n",
    "    # Calculate the similarity between the main article and each article in wiki_list using the cosine similarity of their vectors\n",
    "    wiki['similarity_vector_cosine_similarity'] = np.dot(wiki_main['vector'], wiki['vector']) / (np.linalg.norm(wiki_main['vector']) * np.linalg.norm(wiki['vector']))\n",
    "    # Calculate the similarity between the main article and each article in wiki_list using the jaccard similarity of their vectors\n",
    "    wiki['similarity_vector_jaccard_similarity'] = jaccard_similarity(set(wiki_main['vector']), set(wiki['vector']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "https://en.wikipedia.org/wiki/Machine_learning\n",
      "Machine learning\n",
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5]\n",
      "\n",
      "31\n",
      "https://en.wikipedia.org/wiki/Online_machine_learning\n",
      "Online machine learning\n",
      "In computer science, online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once. Online learning is a common technique used in areas of machine learning where it is computationally infeasible to train over the entire dataset, requiring the need of out-of-core algorithms. It is also used in situations where it is necessary for the algorithm to dynamically adapt to new patterns in the data, or when the data itself is generated as a function of time, e.g., stock price prediction. Online learning algorithms may be prone to catastrophic interference, a problem that can be addressed by incremental learning approaches.\n",
      "\n",
      "29\n",
      "https://en.wikipedia.org/wiki/Meta-learning_(computer_science)\n",
      "Meta-learning (computer science)\n",
      "Meta learning[1][2]\n",
      "is a subfield of machine learning where automatic learning algorithms are applied to metadata about machine learning experiments. As of 2017, the term had not found a standard interpretation, however the main goal is to use such metadata to understand how automatic learning can become flexible in solving learning problems, hence to improve the performance of existing learning algorithms or to learn (induce) the learning algorithm itself, hence the alternative term learning to learn.[1]\n",
      "\n",
      "24\n",
      "https://en.wikipedia.org/wiki/Manifold_regularization\n",
      "Manifold regularization\n",
      "In machine learning, Manifold regularization is a technique for using the shape of a dataset to constrain the functions that should be learned on that dataset. In many machine learning problems, the data to be learned do not cover the entire input space. For example, a facial recognition system may not need to classify any possible image, but only the subset of images that contain faces. The technique of manifold learning assumes that the relevant subset of data comes from a manifold, a mathematical structure with useful properties. The technique also assumes that the function to be learned is smooth: data with different labels are not likely to be close together, and so the labeling function should not change quickly in areas where there are likely to be many data points. Because of this assumption, a manifold regularization algorithm can use unlabeled data to inform where the learned function is allowed to change quickly and where it is not, using an extension of the technique of Tikhonov regularization. Manifold regularization algorithms can extend supervised learning algorithms in semi-supervised learning and transductive learning settings, where unlabeled data are available. The technique has been used for applications including medical imaging, geographical imaging, and object recognition.\n",
      "\n",
      "22\n",
      "https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence\n",
      "Philosophy of artificial intelligence\n",
      "The philosophy of artificial intelligence is a branch of the philosophy of mind and the philosophy of computer science[1] that explores artificial intelligence and its implications for knowledge and understanding of intelligence, ethics, consciousness, epistemology, and free will.[2][3] Furthermore, the technology is concerned with the creation of artificial animals or artificial people (or, at least, artificial creatures; see artificial life) so the discipline is of considerable interest to philosophers.[4] These factors contributed to the emergence of the philosophy of artificial intelligence. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort the wiki_list by similarity to the main article using the dot product of their vectors\n",
    "wiki_list.sort(key=lambda x: x['similarity_vector_dot_product'], reverse=True)\n",
    "\n",
    "# Print the top 5 articles by similarity to the main article using the dot product of their vectors\n",
    "for wiki in wiki_list[:5]:\n",
    "    print(wiki['similarity_vector_dot_product'])\n",
    "    print(\"https://en.wikipedia.org\" + wiki['link'])\n",
    "    print(wiki['title'])\n",
    "    print(wiki['paragraph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "https://en.wikipedia.org/wiki/Machine_learning\n",
      "Machine learning\n",
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5]\n",
      "\n",
      "0.3279680246763151\n",
      "https://en.wikipedia.org/wiki/Computational_learning_theory\n",
      "Computational learning theory\n",
      "In computer science, computational learning theory (or just learning theory) is a subfield of artificial intelligence devoted to studying the design and analysis of machine learning algorithms.[1]\n",
      "\n",
      "0.3218393429334682\n",
      "https://en.wikipedia.org/wiki/Adversarial_machine_learning\n",
      "Adversarial machine learning\n",
      "Adversarial machine learning is the study of the attacks on machine learning algorithms, and of the defenses against such attacks.[1] A survey from May 2020 exposes the fact that practitioners report a dire need for better protecting machine learning systems in industrial applications.[2]\n",
      "\n",
      "0.3175536744149779\n",
      "https://en.wikipedia.org/wiki/Automated_machine_learning\n",
      "Automated machine learning\n",
      "Automated machine learning (AutoML) is the process of automating the tasks of applying machine learning to real-world problems. \n",
      "\n",
      "0.3175536744149779\n",
      "https://en.wikipedia.org/wiki/Quantum_machine_learning\n",
      "Quantum machine learning\n",
      "Quantum machine learning is the integration of quantum algorithms within machine learning programs.[1][2][3][4][5][6][7][8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort the wiki_list by similarity to the main article using the cosine similarity of their vectors\n",
    "wiki_list.sort(key=lambda x: x['similarity_vector_cosine_similarity'], reverse=True)\n",
    "\n",
    "# Print the top 5 articles by similarity to the main article using the cosine similarity of their vectors\n",
    "for wiki in wiki_list[:5]:\n",
    "    print(wiki['similarity_vector_cosine_similarity'])\n",
    "    print(\"https://en.wikipedia.org\" + wiki['link'])\n",
    "    print(wiki['title'])\n",
    "    print(wiki['paragraph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "https://en.wikipedia.org/wiki/Machine_learning\n",
      "Machine learning\n",
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5]\n",
      "\n",
      "1.0\n",
      "https://en.wikipedia.org/wiki/Neural_Designer\n",
      "Neural Designer\n",
      "Neural Designer is a software tool for machine learning based on neural networks, a main area of artificial intelligence research, and contains a graphical user interface which simplifies data entry and interpretation of results.\n",
      "\n",
      "1.0\n",
      "https://en.wikipedia.org/wiki/Machine_Learning_(journal)\n",
      "Machine Learning (journal)\n",
      "Machine Learning  is a peer-reviewed scientific journal, published since 1986.\n",
      "\n",
      "1.0\n",
      "https://en.wikipedia.org/wiki/Special:WhatLinksHere/Machine_learning\n",
      "Pages that link to \"Machine learning\"\n",
      "The following pages link to Machine learning \n",
      "\n",
      "1.0\n",
      "https://en.wikipedia.org/wiki/Category:Artificial_neural_networks\n",
      "Category:Artificial neural networks\n",
      "This category are for articles about artificial neural networks (ANN).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort the wiki_list by similarity to the main article using the jaccard similarity of their vectors\n",
    "wiki_list.sort(key=lambda x: x['similarity_vector_jaccard_similarity'], reverse=True)\n",
    "\n",
    "# Print the top 5 articles by similarity to the main article using the jaccard similarity of their vectors\n",
    "for wiki in wiki_list[:5]:\n",
    "    print(wiki['similarity_vector_jaccard_similarity'])\n",
    "    print(\"https://en.wikipedia.org\" + wiki['link'])\n",
    "    print(wiki['title'])\n",
    "    print(wiki['paragraph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
